# Multi-Agent Translation Pipeline: Semantic Drift Analysis

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Code Quality](https://img.shields.io/badge/code%20quality-MSc%20level-brightgreen.svg)]()
[![Experiment Status](https://img.shields.io/badge/experiment-completed-success.svg)]()

A research project that measures **semantic drift in AI translations** caused by spelling errors using multi-agent systems. This project successfully executed **105 real Claude AI agent calls** to translate text through a language chain (English â†’ French â†’ Hebrew â†’ English) and quantified how translation quality degrades with increasing input errors.

## ðŸŽ¯ Project Overview

**Research Question**: Do spelling errors in source text cause semantic drift when propagated through multi-agent translation pipelines?

**Answer**: **Yes!** Our experiment confirms a **highly significant positive correlation** (r=0.79, p<0.000001) between spelling error rate and semantic drift.

### Key Findings

- **0% errors**: Cosine distance = 0.013 (nearly perfect semantic preservation)
- **25% errors**: Cosine distance = 0.204 (moderate semantic drift)
- **50% errors**: Cosine distance = 0.431 (substantial semantic drift)

The results demonstrate that errors **compound through translation stages**, validating concerns about error propagation in multi-agent AI systems.

## ðŸ“Š Experiment Status: âœ… COMPLETED

This project has been **fully executed and analyzed**:
- âœ… **105 real Claude AI agent invocations** (35 pipeline runs Ã— 3 translation stages)
- âœ… **Real Sentence-BERT embeddings** (all-MiniLM-L6-v2, 384 dimensions)
- âœ… **Publication-quality visualizations** (300 DPI PNG graphs)
- âœ… **Statistically validated results** (p < 0.000001)

### ðŸ“„ Results & Documentation

Complete experiment findings are documented in:
- **[EXPERIMENT_RESULTS.md](EXPERIMENT_RESULTS.md)**: Full experimental report with methodology, statistical analysis, and findings
- **[COMPLETION_SUMMARY.md](COMPLETION_SUMMARY.md)**: Quick overview of accomplishments and key metrics
- **[COMPLETION_REPORT.md](COMPLETION_REPORT.md)**: Detailed completion status and deliverables
- **[PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)**: Implementation metrics and technical summary

### ðŸ“ˆ Generated Artifacts

All experiment outputs are available in the repository:
- `results/experiments/real_pipeline_results.json` - 35 complete translation chains with real AI outputs
- `results/analysis/semantic_drift.csv` - Computed semantic distances using Sentence-BERT
- `results/graphs/*.png` - Three publication-ready visualizations with statistical analysis
- `results/graphs/statistical_analysis.txt` - Complete correlation analysis and p-values

## ðŸ”¬ Methodology

### Translation Pipeline

```
Input Text (with errors)
  â†“
English â†’ French (Claude Task Agent 1)
  â†“
French â†’ Hebrew (Claude Task Agent 2)
  â†“
Hebrew â†’ English (Claude Task Agent 3)
  â†“
Final Output â†’ Semantic Distance Analysis
```

### Error Injection
- **Levels**: 0%, 10%, 20%, 25%, 30%, 40%, 50%
- **Types**: Character substitution, omission, duplication
- **Example**: "The quick brown fox" â†’ "Te qick brwn fx" (50% errors)

### Semantic Analysis
- **Embedding Model**: Sentence-BERT (all-MiniLM-L6-v2)
- **Distance Metrics**: Cosine distance, Euclidean distance
- **Statistical Tests**: Pearson correlation, Spearman correlation

## ðŸ› ï¸ Technology Stack

- **Python 3.12**: Core language with type hints and MSc-level code quality
- **Claude Code Task Agents**: Real AI multi-agent orchestration (105 invocations)
- **sentence-transformers**: State-of-the-art sentence embeddings
- **PyTorch**: Backend for transformer models
- **NumPy & pandas**: Numerical computing and data analysis
- **scipy**: Statistical testing (Pearson, Spearman correlations)
- **matplotlib & seaborn**: Publication-quality visualizations

## ðŸ“¦ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager
- Virtual environment (recommended)

### Setup

1. **Clone and navigate to project**:
   ```bash
   cd multi-agent-translation-pipeline/
   ```

2. **Create virtual environment**:
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

   Key packages installed:
   - sentence-transformers (with PyTorch)
   - numpy, pandas, scipy
   - matplotlib, seaborn
   - scikit-learn

## ðŸš€ Usage (Reproducing Results)

The experiment has been completed, but you can reproduce the analysis:

### 1. Generate Input Sentences with Errors

```bash
python3 -m src.input_generator.generate_inputs
```

Output: `data/input/sentences.json` (5 sentences Ã— 7 error levels = 35 variants)

### 2. Run Translation Pipeline

**Note**: This requires Claude Code Task agents. The translations have already been completed and saved in `results/experiments/real_pipeline_results.json`.

For reference, the helper script shows how results were organized:
```bash
python3 run_real_experiment.py
```

### 3. Analyze Semantic Drift

Compute embeddings and semantic distances from real translations:

```bash
python3 run_real_analysis.py
```

**Output**:
- `results/analysis/semantic_drift.csv` - Distance metrics for all 35 variants
- Console: Progress updates and summary statistics

**Expected console output**:
```
============================================================
REAL SEMANTIC DRIFT ANALYSIS
Using Sentence-BERT Embeddings with Real Claude Agent Data
============================================================

ðŸ“– Loading real results from results/experiments/real_pipeline_results.json...
âœ“ Loaded 35 real translation pipeline results

ðŸ¤– Loading Sentence-BERT model: all-MiniLM-L6-v2
âœ“ Model loaded successfully

ðŸ“Š Computing semantic distances for 35 results...
  Progress: 35/35 (100%)
âœ“ Distance computation complete
```

### 4. Generate Visualizations

Create publication-quality graphs with statistical analysis:

```bash
python3 generate_real_graphs.py
```

**Output**:
- `results/graphs/cosine_distance.png` - Error rate vs cosine distance with correlation stats
- `results/graphs/euclidean_distance.png` - Error rate vs Euclidean distance
- `results/graphs/both_metrics.png` - Side-by-side comparison
- `results/graphs/statistical_analysis.txt` - Complete statistical summary

## ðŸ“‚ Project Structure

```
multi-agent-translation-pipeline/
â”œâ”€â”€ agents/                                # Claude Code agent definitions
â”‚   â”œâ”€â”€ agent_en_to_fr.json               # English â†’ French translator
â”‚   â”œâ”€â”€ agent_fr_to_he.json               # French â†’ Hebrew translator
â”‚   â””â”€â”€ agent_he_to_en.json               # Hebrew â†’ English translator
â”‚
â”œâ”€â”€ src/                                   # Source code modules
â”‚   â”œâ”€â”€ input_generator/                  # Sentence and error generation
â”‚   â”œâ”€â”€ controller/                       # Pipeline orchestration
â”‚   â”œâ”€â”€ analysis/                         # Embedding and distance analysis
â”‚   â””â”€â”€ visualization/                    # Graph generation
â”‚
â”œâ”€â”€ data/input/
â”‚   â””â”€â”€ sentences.json                    # 35 test sentences with errors
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â””â”€â”€ real_pipeline_results.json    # âœ… 35 complete translations (37 KB)
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â””â”€â”€ semantic_drift.csv            # âœ… Computed distances (14 KB)
â”‚   â””â”€â”€ graphs/
â”‚       â”œâ”€â”€ cosine_distance.png           # âœ… 300 DPI visualization (282 KB)
â”‚       â”œâ”€â”€ euclidean_distance.png        # âœ… 300 DPI visualization (255 KB)
â”‚       â”œâ”€â”€ both_metrics.png              # âœ… 300 DPI visualization (320 KB)
â”‚       â””â”€â”€ statistical_analysis.txt      # âœ… Complete stats summary
â”‚
â”œâ”€â”€ tests/                                # Comprehensive test suite
â”‚   â”œâ”€â”€ test_input_generator/
â”‚   â”œâ”€â”€ test_controller/
â”‚   â””â”€â”€ test_analysis/
â”‚
â”œâ”€â”€ run_real_analysis.py                  # Main analysis script (Sentence-BERT)
â”œâ”€â”€ generate_real_graphs.py               # Visualization generator
â”œâ”€â”€ run_real_experiment.py                # Experiment helper/organizer
â”‚
â”œâ”€â”€ EXPERIMENT_RESULTS.md                 # ðŸ“„ Full experimental report
â”œâ”€â”€ COMPLETION_SUMMARY.md                 # ðŸ“„ Quick findings overview
â”œâ”€â”€ COMPLETION_REPORT.md                  # ðŸ“„ Detailed completion status
â”œâ”€â”€ PROJECT_SUMMARY.md                    # ðŸ“„ Implementation metrics
â”œâ”€â”€ README.md                             # This file
â””â”€â”€ requirements.txt                      # Python dependencies
```

## ðŸ“ˆ Sample Results

### Real Translation Example

**Input (0% errors)**:
```
"The quick brown fox jumps over the lazy dog while the sun shines brightly in the clear blue sky above"
```

**Translations**:
- ENâ†’FR: "Le renard brun rapide saute par-dessus le chien paresseux..."
- FRâ†’HE: "×”×©×•×¢×œ ×”×—×•× ×”×ž×”×™×¨ ×§×•×¤×¥ ×ž×¢×œ ×”×›×œ×‘ ×”×¢×¦×œ×Ÿ..." (Hebrew RTL)
- HEâ†’EN: "The quick brown fox jumps over the lazy dog while the sun shines brightly in the clear blue skies above"

**Semantic Distance**: 0.013 (nearly identical)

---

**Input (50% errors)**:
```
"Te qick brwn fx jmps ovr te lzy dg wile te sn shnes brightly n te cler blu sky abve"
```

**Semantic Distance**: 0.431 (substantial drift)

### Statistical Summary

| Error Rate | Cosine Distance | Interpretation |
|------------|----------------|----------------|
| 0%         | 0.013 Â± 0.007  | Nearly perfect |
| 10%        | 0.083 Â± 0.057  | Small drift |
| 20%        | 0.184 Â± 0.108  | Moderate drift |
| 25%        | 0.204 Â± 0.146  | Moderate drift |
| 30%        | 0.288 Â± 0.088  | Substantial drift |
| 40%        | 0.256 Â± 0.120  | Substantial drift |
| 50%        | 0.431 Â± 0.112  | High drift |

**Correlation**: r = 0.79, p < 0.000001 (highly significant)

## ðŸ§ª Testing

### Run Complete Test Suite

```bash
pytest tests/ -v
```

### Run with Coverage

```bash
pytest tests/ --cov=src --cov-report=term-missing --cov-report=html
```

### Code Quality

```bash
# Format code
black src/ tests/

# Type checking
mypy src/

# Linting
pylint src/
```

## ðŸŽ“ Academic Context

**Course**: MSc Computer Science - Multi-Agent Systems
**Institution**: Reichman University, IL
**Project Type**: Research Experiment with Real AI Agents


## ðŸ“š Key Insights

### What We Learned

1. **Error Propagation is Real**: Spelling errors don't just affect individual translationsâ€”they compound through multi-agent pipelines

2. **Quantifiable Impact**: Each 10% increase in error rate adds ~0.05-0.10 to semantic distance

3. **Robustness Has Limits**: While Claude AI handles moderate errors well (â‰¤25%), severe corruption (50%) causes substantial semantic drift

4. **Multi-Agent Vulnerability**: Sequential AI agents create cumulative error effects that single-agent systems avoid

### Practical Applications

- **Input Validation**: Motivates spell-checking and error correction before AI processing
- **Quality Monitoring**: Provides baseline metrics for translation quality degradation
- **Pipeline Design**: Informs decisions about multi-agent vs single-agent architectures
- **Error Budgets**: Quantifies acceptable input error rates for production systems

## ðŸ”— Related Work

### Research References

- Semantic Drift in Multilingual Representations ([MIT Press](https://direct.mit.edu/coli/article/46/3/571/93376))
- COMET: Neural Framework for MT Evaluation ([ACL Anthology](https://aclanthology.org/2020.emnlp-main.213.pdf))
- Sentence-BERT Documentation ([SBERT.net](https://sbert.net/))

### Technical Dependencies

- [sentence-transformers](https://sbert.net/) - Sentence embeddings
- [PyTorch](https://pytorch.org/) - Deep learning backend
- [scikit-learn](https://scikit-learn.org/) - Distance metrics
- [matplotlib](https://matplotlib.org/) - Plotting
- [seaborn](https://seaborn.pydata.org/) - Statistical visualization

## ðŸ“„ License

Academic Research Project
**Institution**: Reichman University, IL

## ðŸ‘¥ Authors

**Niv Ben Salmon** & **Omer Ben Salmon**
MSc Computer Science Students
Reichman University, Israel

